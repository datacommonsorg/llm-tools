{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Grounding LLM statistics facts using Retrieval Interleaved Generation (RIG)\n",
        "\n",
        "In this notebook, we share promising, early research advancements that tackle the challenge of provenance around real-world statistical data. This notebook connects to DataGemma, the first [open model](https://huggingface.co/google/datagemma-rig-27b-it) designed to connect large language models with the extensive, real-world data housed within Google's [Data Commons](https://datacommons.org).\n",
        "\n",
        "This novel approach fine-tunes [Gemma 2](https://ai.google.dev/gemma/docs) to recognize when it needs to replace a generated number with more accurate information from Data Commons. Think of it as the model double-checking its work against a trusted source. More technical details of this approach can be found in this [paper](https://datacommons.org/link/DataGemmaPaper).\n",
        "\n",
        "This demo is based on a finetuned Gemma2 27B model.\n",
        "\n",
        "Please read [Gemma Terms of Use](https://ai.google.dev/gemma/terms).\n",
        "\n",
        "***Disclaimer:***\n",
        "\n",
        "*You're accessing a very early version of DataGemma. It is meant for trusted tester use (primarily for academic and research use) and not yet ready for commercial or general public use. This version was trained on a very small corpus of examples and may exhibit unintended, and at times controversial or inflammatory behavior. Please anticipate errors and limitations as we actively develop this large language model interface.*\n",
        "\n",
        "*Your feedback and evaluations are critical to refining DataGemma's performance and will directly contribute to its training process. Known limitations are detailed in the paper, and we encourage you to consult it for a comprehensive understanding of DataGemma's current capabilities.*"
      ],
      "metadata": {
        "id": "tWMgvkQRHSet"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 0: Setup\n",
        "\n",
        "To run this colab, you will need to use the A100 GPU and High-RAM runtime in Colab. With this runtime configuration, the total runtime of this notebook would take about 20 minutes.\n",
        "\n",
        "You also need authentication for model and data access:\n",
        "\n",
        "*   **Hugging Face Token**. To obtain the token, login to your Hugging Face account [token settings](https://huggingface.co/settings/tokens) to create a new token. Copy this token and store it on the colab notebook `Secrets` section with Name `HF_TOKEN`.\n",
        "\n",
        "*   **Data Commons API Key**. Register for an API key from Data Commons [API key portal](https://apikeys.datacommons.org) and make sure to enable `Data Commons NL API`. Once you get the API key, store it on the colab notebook `Secrets` section with Name `DC_API_KEY`.\n",
        "\n",
        "Toggle the \"Notebook access\" button to enable all these secrets.\n",
        "\n",
        "Then install the required libraries."
      ],
      "metadata": {
        "id": "wEPZcQMDHwS1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpL9Rqb_PfxS",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install -q git+https://github.com/datacommonsorg/llm-tools\n",
        "!pip install -q bitsandbytes accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Load the model\n",
        "\n",
        "This section loads the finetuned Gemma2 27B model from Huggingface and creates a transformer model wrapper than can be used in the Retrieval Interleaved Generation (RIG) workflow. More technical details of this approach can be found in the [paper](https://datacommons.org/link/DataGemmaPaper)."
      ],
      "metadata": {
        "id": "-3A0T9OXIDAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "import data_gemma as dg\n",
        "\n",
        "from google.colab import userdata\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "# Initialize Data Commons API client\n",
        "DC_API_KEY = userdata.get('DC_API_KEY')\n",
        "dc = dg.DataCommons(api_key=DC_API_KEY)\n",
        "\n",
        "\n",
        "# Get finetuned Gemma2 model from HuggingFace\n",
        "HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "\n",
        "nf4_config = BitsAndBytesConfig(\n",
        "   load_in_4bit=True,\n",
        "   bnb_4bit_quant_type=\"nf4\",\n",
        "   bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "model_name = 'google/datagemma-rig-27b-it'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, token=HF_TOKEN)\n",
        "datagemma_model = AutoModelForCausalLM.from_pretrained(model_name,\n",
        "                                             device_map=\"auto\",\n",
        "                                             quantization_config=nf4_config,\n",
        "                                             torch_dtype=torch.bfloat16,\n",
        "                                             token=HF_TOKEN)\n",
        "\n",
        "# Build the LLM Model stub to use in RIG flow\n",
        "datagemma_model_wrapper = dg.HFBasic(datagemma_model, tokenizer)"
      ],
      "metadata": {
        "id": "eAOwrW6vlwyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Pick or enter a query for RIG\n",
        "\n",
        "You can selected a query or enter your own query to test RIG.\n"
      ],
      "metadata": {
        "id": "xM_jH5Iakffe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title Pick a query from a sample list{ run: \"auto\" }\n",
        "QUERY = \"What progress has Pakistan made against health goals?\" #@param [\"In which countries are more women getting college degrees than men?\",\"Which US counties share a very similar demographic composition to the US overall in terms of gender, age and racial breakdown?\",\"Are there significant differences in the prevalence of various types of disabilities (such as vision, hearing, mobility, cognitive) between Dallas and Houston?\",\"Which countries have the highest life expectancy?\",\"How does the size of household compare across counties in Utah vs. California?  Does it change between owned vs. rental properties?\",\"What progress has Pakistan made against health goals?\",\"Has the average lifespan increased globally?\",\"Compare Cambridge, MA and Palo Alto, CA in terms of demographics, education, and economy stats.\",\"Are there countries in the world where the forest area has actually increased?\",\"Has women's participation in the workforce around the world increased over the last few years?\",\"Show me how maternal mortality has declined in the last few years\",\"What are some interesting trends in Sunnyvale spanning gender, age, race, immigration, health conditions, economic conditions, crime and education?\",\"Based on the distribution of foreign language speakers compare the diversity of people in: NYC, Seattle, Austin, Chicago and Tampa\",\"Does an increase in female participation in education result in a higher number of women holding political office?\",\"Compare progress on poverty in Mexico, Nigeria and Pakistan\"]\n"
      ],
      "metadata": {
        "id": "jZRYhyuGkIJg",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Use your own query (Please see disclaimer at the top)\n",
        "QUERY = 'What progress has Pakistan made against health goals?' #@param {type:\"string\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "hB-DKl0BxlN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Run RIG and Print Output\n"
      ],
      "metadata": {
        "id": "cAbaiaCORoSl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "import textwrap\n",
        "\n",
        "def display_chat(prompt, text):\n",
        "  formatted_prompt = \"<font size='+1' color='brown'>üôã‚Äç‚ôÇÔ∏è<blockquote>\" + prompt + \"</blockquote></font>\"\n",
        "  text = text.replace('‚Ä¢', '  *')\n",
        "  text = textwrap.indent(text, '> ', predicate=lambda _: True)\n",
        "  formatted_text = \"<font size='+1' color='teal'>ü§ñ\\n\\n\" + text + \"\\n</font>\"\n",
        "  return Markdown(formatted_prompt+formatted_text)\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('‚Ä¢', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
        "\n",
        "\n",
        "ans = dg.RIGFlow(llm=datagemma_model_wrapper, data_fetcher=dc, verbose=False).query(query=QUERY)\n",
        "Markdown(textwrap.indent(ans.answer(), '> ', predicate=lambda _: True))\n",
        "\n",
        "\n",
        "display_chat(QUERY, ans.answer())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6hawX4Eg1knC",
        "outputId": "a4218ee5-8c8d-4538-b77e-83eac90c11fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "... calling HF Pipeline API \"What progress has Pakistan made against health goa...\"\n",
            "... calling DC with \"what was the life expectancy in Pakistan in 2000?\"\n",
            "... calling DC with \"what was the life expectancy in Pakistan in 2020?\"\n",
            "... calling DC with \"what was the maternal mortality rate in Pakistan in 2000?\"\n",
            "... calling DC with \"what was the maternal mortality rate in Pakistan in 2018?\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<font size='+1' color='brown'>üôã‚Äç‚ôÇÔ∏è<blockquote>What progress has Pakistan made against health goals?</blockquote></font><font size='+1' color='teal'>ü§ñ\n\n> \n> \n> Pakistan has made some progress against its health goals, but significant challenges remain. \n> \n> **Here are some key points:**\n> \n> **Progress made:**\n> \n> * **Increased life expectancy:** Life expectancy at birth has increased from [__DC__#1(62.102 yr [1] || 61.8 years)] in 2000 to [__DC__#2(66.269 yr [2] || 67.2 years)] in 2020.\n> * **Reduced maternal mortality:** Maternal mortality ratio has declined from [__DC__#3(387.3715 Per 100,000 live births [3]* || 276 per 100,000 live births)] in 2000 to [__DC__#4(177.7277 Per 100,000 live births [4]* || 140)] in 2018.\n> * **Improved immunization coverage:** Immunization coverage for key vaccines like measles and polio has improved, though challenges like vaccine hesitancy persist.\n> * **Expansion of healthcare infrastructure:** The government has invested in expanding healthcare facilities, particularly in rural areas.\n> \n> **Challenges remaining:**\n> \n> * **High burden of infectious diseases:**  Pakistan still faces a significant burden from infectious diseases like tuberculosis, malaria, and HIV/AIDS.\n> * **Rising non-communicable diseases**: There is a growing prevalence of non-communicable diseases like diabetes, heart disease, and cancer, largely attributed to lifestyle factors and aging population.\n> * **Malnutrition:** Malnutrition, both undernutrition and overnutrition, remains a serious public health problem, affecting a large proportion of the population.\n> * **Limited access to healthcare:** Access to quality healthcare remains limited, especially in rural and underserved areas.\n> \n> * **Inadequate healthcare financing:** Pakistan's healthcare system is underfunded, leading to shortages of essential medicines, supplies, and trained personnel.\n> * **Weak health system:** The public health system faces numerous weaknesses, including lack of coordination, poor management, and insufficient capacity.\n> \n> **Key initiatives and programs:**\n> \n> * **National Health Vision 2016-2025:** This strategic document outlines the government's plan for improving health outcomes and strengthening the healthcare system.\n> * **Expanded Programme on Immunization (EPI):** The EPI aims to provide routine vaccinations to all children and pregnant women.\n> * **Lady Health Worker Program:** This program empowers women as community-based health workers, providing essential healthcare services at the grassroots level.\n> \n> **Conclusion:**\n> \n> Pakistan has made progress in achieving some of its health goals, but significant challenges remain. Addressing these challenges will require sustained commitment from the government, civil society, and the private sector, as well as increased investment in public health infrastructure and human resources.\n> \n> **Note:**\n> \n> This information is based on publicly available data and reports. For the most up-to-date information, please refer to relevant Pakistani government and international organizations like the WHO.\n> \n> #### FOOTNOTES ####\n> [1] - Per datacatalog.worldbank.org, value was 62.102 yr in 2000. See more at https://datacommons.org/explore#q=what%20was%20the%20life%20expectancy%20in%20Pakistan%20in%202000%3F&mode=toolformer_rig\n> [2] - Per datacatalog.worldbank.org, value was 66.269 yr in 2020. See more at https://datacommons.org/explore#q=what%20was%20the%20life%20expectancy%20in%20Pakistan%20in%202020%3F&mode=toolformer_rig\n> [3] - Per Global SDG Database, value was 387.3715 Per 100,000 live births in 2000. See more at https://datacommons.org/explore#q=what%20was%20the%20maternal%20mortality%20rate%20in%20Pakistan%20in%202000%3F&mode=toolformer_rig\n> [4] - Per Global SDG Database, value was 177.7277 Per 100,000 live births in 2018. See more at https://datacommons.org/explore#q=what%20was%20the%20maternal%20mortality%20rate%20in%20Pakistan%20in%202018%3F&mode=toolformer_rig\n</font>"
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# More Information on Retrieval Interleaved Generation (RIG)\n",
        "\n",
        "Retrieval Interleaved Generation (RIG): This novel approach fine-tunes Gemma 2 to recognize when it needs to replace a generated number with more accurate information from Data Commons. Think of it as the model double-checking its work against a trusted source.\n",
        "\n",
        "Here's how RIG works:\n",
        "1. User Query: A user submits a query to the LLM.\n",
        "2. Initial Response & Data Commons Query: The DataGemma model (based on the Gemma 2 27 billion parameter (27B) model and fully fine-tuned for this RIG task) generates a response, which includes a natural language query for Data Commons' existing natural language interface,  specifically designed to retrieve relevant data.\n",
        "3. Data Retrieval & Correction: Data Commons is queried, and the data are retrieved. These data, along with source information and a link, are then used to replace potentially inaccurate numbers in the initial response.\n",
        "4. Final Response with Source Link: The final response is presented to the user, including a link to the source data and metadata in Data Commons for transparency and verification.\n",
        "\n",
        "In the above example, notice the questions being asked of Data Commons (eg \"what was the life expectancy in Pakistan in 2000?\") which is being used to compare the initial LLM response in `[__DC__#1(62.102 yr [1] || 61.8 years)]`. `61.8 years` is the  value generated by Gemma2 27B. DataGemma is trained to query Data Commons with \"what was the life expectancy in Pakistan in 2000?\". Statistics from the World Bank along with citations to the initial source are returned by Data Commons and replaced in the final response.  "
      ],
      "metadata": {
        "id": "BKmhc6ROraW8"
      }
    }
  ]
}